{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDE_DNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTsNK1TvkLRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "8eeb7339-f9ff-4e51-fc31-528bdcc179ce"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time, os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0-_Sm9EAhVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_predicted_fn(inp, op, derv):\n",
        "    \"\"\"\n",
        "    For plotting predictions\n",
        "    \"\"\"\n",
        "    \n",
        "    # c = op[0] - (inp[0]**3)/3 \n",
        "\n",
        "    plt.plot(inp,op)\n",
        "    plt.title(\"x vs t\")\n",
        "    plt.show()\n",
        "\n",
        "    # actual derivative values\n",
        "    actual_derv = [i**2 - 3 for i in inp]\n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.title(\"x_t vs t\")\n",
        "    plt.plot(inp, derv, label = \"pred\")\n",
        "    plt.scatter(inp, actual_derv, c='r' ,label = 'actual')\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVo78_DCkWvh",
        "colab_type": "code",
        "outputId": "32a14822-78a0-4eac-cf1b-07a94873ffb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        }
      },
      "source": [
        "# input to neural network\n",
        "t = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
        "\n",
        "epochs = 100000\n",
        "# initial learning rate\n",
        "lr = 0.01\n",
        "l_rate = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "# network architecture\n",
        "ly1 = tf.layers.dense(inputs=t, units=640, activation=tf.nn.sigmoid,\n",
        "                                  kernel_initializer=tf.random_normal_initializer(0., .1),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))\n",
        "ly2 = tf.layers.dense(inputs=ly1, units=320, activation=tf.nn.relu,\n",
        "                                  kernel_initializer=tf.random_normal_initializer(0., .1),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))\n",
        "ly3 = tf.layers.dense(inputs=ly2, units=16, activation=tf.nn.relu,\n",
        "                                  kernel_initializer=tf.random_normal_initializer(0., .1),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))\n",
        "ly4 = tf.layers.dense(inputs=ly3, units=8, activation=tf.nn.relu,\n",
        "                                  kernel_initializer=tf.random_normal_initializer(0., .1),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))\n",
        "op = tf.layers.dense(inputs=ly1, units=1, activation=None)\n",
        "\n",
        "# input range is [1,inp_length]\n",
        "inp_length = 100\n",
        "\n",
        "# computing gradient\n",
        "x_t = tf.gradients(op,t)[0]\n",
        "\n",
        "# loss function\n",
        "# equation: dx/dt = t^2 -3\n",
        "loss = tf.reduce_mean(tf.square(x_t - t*t + 3))\n",
        "\n",
        "# equation: dx/dt = 6x^2*t\n",
        "# loss = tf.reduce_mean(tf.square(x_t - 6*op[0]*op[0]*t))\n",
        "\n",
        "# optimizer\n",
        "opt = tf.train.AdamOptimizer(learning_rate = lr).minimize(loss)\n",
        "# opt = tf.train.GradientDescentOptimizer(learning_rate = lr).minimize(loss)\n",
        "\n",
        "# training data\n",
        "time_var = np.array([i for i in range(1,inp_length+1)])\n",
        "time_var = time_var[:, np.newaxis]\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    losses = []\n",
        "    for i in range(epochs):\n",
        "        count = 0\n",
        "        # adaptive learning rate to avoid skipping minima\n",
        "        if((i+1)%20000 == 0):\n",
        "            lr = 0.1*lr\n",
        "            print(\"learning rate:\", lr)\n",
        "        \n",
        "        inp = np.reshape(time_var, [-1,1])\n",
        "        x,_ = sess.run([op,opt], feed_dict={t: inp, l_rate: lr})\n",
        "        losses.append(loss.eval({t: time_var, l_rate: lr}))\n",
        "            \n",
        "        if(i+1 == epochs):\n",
        "            print(\"Epoch :\", i, end=\" \")\n",
        "            print(\"loss : \",loss.eval({t: time_var}))\n",
        "            # print(\"Input : \",inp,\"output : \",x,\"loss : \",loss.eval({t: time_var, l_rate: lr}))\n",
        "            # print(\"Derivative: \",x_t.eval({t:inp, l_rate: lr}))\n",
        "            # count = count + 1\n",
        "        if(i % 10000 == 0):\n",
        "            print(\"Epoch :\", i, end=\" \")\n",
        "            print(\"loss : \",loss.eval({t: time_var}))\n",
        "            \n",
        "        #     print(\"x : \", x,\"loss : \",loss.eval({t: time_var, l_rate: lr}))\n",
        "        #     print(\"x_t: \",x_t.eval({t:inp, l_rate: lr}))\n",
        "\n",
        "    time_test = np.array([i for i in range(1,inp_length+1)])\n",
        "    time_test = time_test[:, np.newaxis]\n",
        "    # print(op.eval({t: time_test}))\n",
        "    pred = list(op.eval({t: time_test}))\n",
        "    pred = [i[0] for i in pred]\n",
        "    derivatives = list(x_t.eval({t: time_test}))\n",
        "    derivatives = [i[0] for i in derivatives]\n",
        "    inp = [i for i in range(1,inp_length+1)]\n",
        "    plot_predicted_fn(inp, pred, derivatives)\n",
        "    \n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 loss :  20482904.0\n",
            "Epoch : 10000 loss :  11886109.0\n",
            "learning rate: 0.001\n",
            "Epoch : 20000 loss :  6601301.0\n",
            "Epoch : 30000 loss :  3156330.2\n",
            "learning rate: 0.0001\n",
            "Epoch : 40000 loss :  1112562.6\n",
            "Epoch : 50000 loss :  171146.8\n",
            "learning rate: 1e-05\n",
            "Epoch : 60000 loss :  2553.2632\n",
            "Epoch : 70000 loss :  43.26041\n",
            "learning rate: 1.0000000000000002e-06\n",
            "Epoch : 80000 loss :  121.81774\n",
            "Epoch : 90000 loss :  2843.983\n",
            "learning rate: 1.0000000000000002e-07\n",
            "Epoch : 99999 loss :  251.86275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEICAYAAAB1f3LfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAE/CAYAAAD7bgqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJyIiIiIiUkT+H6Y/Hzf7yND4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve9-XWLlwCWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8qClcuX8DJq",
        "colab_type": "code",
        "outputId": "13e298e4-5db5-4299-96c6-0ace4b7fa17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "input_size = 1\n",
        "hidden_size = 64\n",
        "# num_classes = 10\n",
        "num_epochs = 50000\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# # MNIST dataset \n",
        "# train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "#                                            train=True, \n",
        "#                                            transform=transforms.ToTensor(),  \n",
        "#                                            download=True)\n",
        "\n",
        "# test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "#                                           train=False, \n",
        "#                                           transform=transforms.ToTensor())\n",
        "\n",
        "# # Data loader\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "#                                            batch_size=batch_size, \n",
        "#                                            shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "#                                           batch_size=batch_size, \n",
        "#                                           shuffle=False)\n",
        "\n",
        "#Train data\n",
        "\n",
        "train_data = np.array([[float(i)] for i in range(1,101)])\n",
        "# train_data = train_data[:, np.newaxis]\n",
        "train_data = torch.from_numpy(train_data)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.tanh = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size*2)\n",
        "        self.fc3 = nn.Linear(hidden_size*2, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc2(out)\n",
        "        # out = self.tanh(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size).to(device)\n",
        "\n",
        "# def my_loss(output, inp):\n",
        "#     # loss = torch.mean((output - target)**2)\n",
        "#     losses = []\n",
        "#     for i in inp:\n",
        "#       x = torch.autograd.Variable(i,requires_grad=True)\n",
        "#       print(x)\n",
        "#       y = model(x.float())\n",
        "#       # print(\"in loss fn: \",y)\n",
        "#       y.backward()\n",
        "#       losses.append((x.grad - x**2 + 3) ** 2)\n",
        "    \n",
        "#     losses = torch.FloatTensor(losses)\n",
        "#     print(losses)\n",
        "#     loss = torch.mean(losses)\n",
        "#     return loss\n",
        "\n",
        "\n",
        "def my_loss(output, inp):\n",
        "    x = torch.autograd.Variable(inp,requires_grad=True)\n",
        "    y = model(x.float())\n",
        "    y.backward()\n",
        "    loss = (x.grad - x**2 + 3) ** 2\n",
        "    # print(x.grad)\n",
        "    return loss\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "# total_step = len(train_loader)\n",
        "total_step = 100\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Epoch :\", epoch)\n",
        "    # for i, inp in enumerate(train_loader):  \n",
        "    for inp in train_data:    \n",
        "        # Forward pass\n",
        "        # i = i.reshape(-1,1).to(device)\n",
        "        # print(inp, type(inp))\n",
        "        outputs = model(inp.float())\n",
        "        # print(outputs)\n",
        "        # loss = criterion(outputs, inp.float())\n",
        "        \n",
        "        loss = my_loss(outputs, inp)\n",
        "        \n",
        "        # print(loss.item())\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # if (i+1) % 100 == 0:\n",
        "        #     print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "        #            .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    print(loss)\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "# with torch.no_grad():\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.reshape(-1, 28*28).to(device)\n",
        "#         labels = labels.to(device)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# # Save the model checkpoint\n",
        "# torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 1\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 2\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 3\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 4\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 5\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 6\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 7\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 8\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 9\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 10\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 11\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 12\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 13\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 14\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 15\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 16\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 17\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 18\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 19\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 20\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 21\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 22\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 23\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 24\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 25\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 26\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 27\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 28\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 29\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 30\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 31\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 32\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 33\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 34\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 35\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 36\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 37\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 38\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 39\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 40\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 41\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 42\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 43\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 44\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 45\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 46\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 47\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 48\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 49\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 50\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 51\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 52\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 53\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 54\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 55\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 56\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 57\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 58\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 59\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 60\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 61\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 62\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 63\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 64\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 65\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 66\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 67\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 68\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 69\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 70\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 71\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 72\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 73\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 74\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 75\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 76\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 77\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 78\n",
            "tensor([99940025.5180], dtype=torch.float64, grad_fn=<PowBackward0>)\n",
            "Epoch : 79\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-014f72e93552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# if (i+1) % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkfxnVyJE45J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dkrYiWBE43O",
        "colab_type": "code",
        "outputId": "d53a2414-d2aa-4576-daf7-920e6dfe03c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# Keras implementation\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import backend as K\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewrnhpKpNaIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(actual,pred):\n",
        "    loss = K.mean(K.sum(K.square((actual - pred )/10)))\n",
        "    grads = K.gradients(model.output, model.input)[0]\n",
        "    # loss = (grads - model.input**2 + 3) **2\n",
        "    inp = K.variable(model.input)\n",
        "    print(grads - inp**2 + 3 )\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzwUZFALE4y4",
        "colab_type": "code",
        "outputId": "ac744367-7ebf-44f1-c53f-a51c12fa08fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data = np.array([[float(i)] for i in range(1,101)])\n",
        "# train_data = train_data[:, np.newaxis]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=1, activation='tanh'))\n",
        "model.add(Dense(32, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# compile the keras model\n",
        "model.compile(loss=custom_loss, optimizer='adam', metrics=['accuracy'])\n",
        "# fit the keras model on the dataset\n",
        "X = train_data\n",
        "hist = model.fit(X, X, epochs=10, batch_size=10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-3db53c392707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# compile the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 345\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \"\"\"\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-dd3055d353bb>\u001b[0m in \u001b[0;36mcustom_loss\u001b[0;34m(actual, pred)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# loss = (grads - model.input**2 + 3) **2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1686\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m           shape=shape)\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1851\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitial_value_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             raise ValueError(\"initial_value must have a shape specified: %s\" %\n\u001b[0;32m-> 1853\u001b[0;31m                              self._initial_value)\n\u001b[0m\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0;31m# If 'initial_value' makes use of other variables, make sure we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: initial_value must have a shape specified: Tensor(\"dense_46_input:0\", shape=(?, 1), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhiA6PF42gSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}